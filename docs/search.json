[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "cv\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTraffic Summary of each of WI’s 72 County Profiles\n\n\n\nShiny\n\n\nData Viz\n\n\n\nCrash data summaries for 72 counties. This has dynamic maps showing crashes and hotspots.\n\n\n\nMay 4, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWisDOT Crash Comparison Dashboard\n\n\n\nShiny\n\n\nData Viz\n\n\n\nI was asked to create a visual that compares crashes by quarter. This was previously done manually in Excel, needing to find the number of crashes for each crash flag/type…\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWorking with API and JSON format\n\n\n\nAPI\n\n\nData analysis\n\n\n\nThe task was to find the average sentence length of OWI (operating while intoxicated) offenders on their 3rd or more OWI citation.\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWisDOT Crash Comparison Dashboard\n\n\n\nShiny\n\n\nData Viz\n\n\n\nI was asked to create a visual that compares crashes by quarter. This was previously done manually in Excel, needing to find the number of crashes for each crash flag/type…\n\n\n\nOct 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nWisconsin Traffic Crash Facts\n\n\n\nQuarto\n\n\n\nThis is a crash facts book done in a web format. I was excited to use the newly released Quarto by Posit. The book provides many tables and charts of crash data. Past…\n\n\n\nAug 1, 2022\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysis of OWI ratios\n\n\n\nData analysis\n\n\n\nFind risk ratios of OWI (operating while intoxicated) offenders from across multiple datasets.\n\n\n\nNov 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nCoffee Roasting Profiler\n\n\n\nShiny\n\n\nData Viz\n\n\n\nAn ameateur coffee roaster, I made this dashboard to visualize my roast profiles.\n\n\n\nAug 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nWisDOT Crash Statistics Dashboard\n\n\n\nShiny\n\n\nData Viz\n\n\n\nWisDOT uses Community Maps, a website that displays a map of crashes in near real-time. I wanted the user…\n\n\n\nJan 4, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nR Package: wisdotcrashdatabase\n\n\n\nPackage development\n\n\n\nI developed this package to make data import and data analysis much easier inside an R environment.\n\n\n\nAug 20, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSubway-Style Bike Path Map of Madison, WI\n\n\n\nQGIS\n\n\nIllustrator\n\n\n\n\n\n\n\nNov 18, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nArticle on Madison’s ‘Lost City’ - A Look Into the Failed 1920’s Lake Forest Development\n\n\n\nWriter\n\n\n\n\n\n\n\nJul 24, 2016\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/roasting_dashboard.html",
    "href": "projects/roasting_dashboard.html",
    "title": "Coffee Roasting Profiler",
    "section": "",
    "text": "Dashboard  Code\n\nWhat I learned\nThe tricky part was adding the RoR (rate of return) curves (the blue and purple) onto the graph as this is calculated via an algorithm written in Python inside Artisan software. I found this piece of code and rewrote part of it so it would work for my app. Next I used the reticulate package so the app can read Python code.\n\n\nHighlighted packages\nThe dashboard uses reticulate, formattable, and DT under a golem framework."
  },
  {
    "objectID": "projects/json_api.html",
    "href": "projects/json_api.html",
    "title": "Working with API and JSON format",
    "section": "",
    "text": "What I learned\nThis was done it two parts 1) Writing functions that pulls data from our court case API into a JSON format over a certain time period and for certain citations. This data was flattened and compiled into a single dataframe and exported. And 2) Finding the sentence length for a certain citation for each case. This was tricky as one case may have multiple citations while sentence lengths can be found in multiple branches of the flattened JSON. I solved this issue by finding which branch a certain location was found and replaced part of the branch name with where the sentence length location. I was able to extract the sentence length with this ‘renaming.’ to calculate the average sentence length.\n\n\nHighlighted packages\njsonlite, httr"
  },
  {
    "objectID": "projects/crash_facts.html",
    "href": "projects/crash_facts.html",
    "title": "Wisconsin Traffic Crash Facts",
    "section": "",
    "text": "#  2021 Wisconsin Crash Facts\n\nWhat I learned\nI learned YAML and Quarto! I spent the most time writing functions to standardize the table format, render charts, and to more easily aggregate the data.\n\n\nHighlighted packages\ngt, gtExtras, quarto"
  },
  {
    "objectID": "projects/crash_comparison.html",
    "href": "projects/crash_comparison.html",
    "title": "WisDOT Crash Comparison Dashboard",
    "section": "",
    "text": "View the Dashboard\n\nWhat I learned\nKnowing this dashboard would be viewed on a variety of screen sizes, I used dynamic font sizes (i.e. 1.2em) as opposed to static font sizes (i.e. 12pt). I also wrote CSS as to make printing of the entire dashboard possible on two pages.\n\n\nHighlighted packages\nThe dashboard uses dashboardthemes, ggplot2 and ggtext using the golem framework."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jacci Ziebert",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Jacci Ziebert",
    "section": "",
    "text": "I am a data analyst and R programmer. I’ve built an R package to improve work flow, developed Shiny web apps, and automated long reports. I like to look for ways to automate manual tasks and to translate data into a concise and meaningful visual for a general audience in either a dashboard or report format. While I’m typically the sole R programmer, I write projects for longevity - having documentation and a reproducible environment are crucial elements if we\nMy passion for R sparked when I felt frustrated of the mundane workflow at my previous job from SAS/Excel and knew there had to be a better way. I took an online programming class and immediately applied what I learned to my job.\nWhen I’m not coding, I enjoy graphing my coffee roasts, playing strategy board games, and gravel cycling.\nwriting code within weeks."
  },
  {
    "objectID": "about.html#greetings",
    "href": "about.html#greetings",
    "title": "Jacci Ziebert",
    "section": "",
    "text": "I am a data analyst and R programmer. I’ve built an R package to improve work flow, developed Shiny web apps, and automated long reports. I like to look for ways to automate manual tasks and to translate data into a concise and meaningful visual for a general audience in either a dashboard or report format. While I’m typically the sole R programmer, I write projects for longevity - having documentation and a reproducible environment are crucial elements if we\nMy passion for R sparked when I felt frustrated of the mundane workflow at my previous job from SAS/Excel and knew there had to be a better way. I took an online programming class and immediately applied what I learned to my job.\nWhen I’m not coding, I enjoy graphing my coffee roasts, playing strategy board games, and gravel cycling.\nwriting code within weeks."
  },
  {
    "objectID": "projects/county_profiles.html",
    "href": "projects/county_profiles.html",
    "title": "Traffic Summary of each of WI’s 72 County Profiles",
    "section": "",
    "text": "Dane County’s Traffic Safety Summary\n\nWhat I learned\nI learned to create a parameterized R Markdown. The maps use our crash API.\n\n\nHighlighted packages\nplotly, googleway, and kableExtra"
  },
  {
    "objectID": "projects/crash_dashboard.html",
    "href": "projects/crash_dashboard.html",
    "title": "WisDOT Crash Statistics Dashboard",
    "section": "",
    "text": "What I learned\nThrough performance testing via shinyloadtest, I found an enormous bottleneck through simply loading the data. As a solution, I created a SQLite database as the database is saved locally inside the package. While this dramitically improved performance, data was still being mapped on-the-fly. Ideally the data should be stored in a spatial database. This app also uses modules so server and ui are much cleaner while the code is easier to debug.\n\n\nHighlighted packages\nThe dashboard uses plotly, leaflet, leaflet.extras2 and leafgl under a golem framework."
  },
  {
    "objectID": "projects/crash_package.html",
    "href": "projects/crash_package.html",
    "title": "R Package: wisdotcrashdatabase",
    "section": "",
    "text": "What I learned\nThe typical work flow was using SAS to get the data and then doing the analysis in Excel. Doing everything in R would be more efficient. It came to a point where I was constantly sourcing the same scripts so it was logical to turn these scripts into an R package. The package has functions that query certain crash flags so I don’t have to look up the actual query. On the backend, data is stored in a SQL database, one that I created and updates automatically on a weekly basis. Importing data multiple times a day and unable to store tihs data in the cloud, I found duckdb to be the fastest solution (as compared to csv, SQLite, and fst).\n\n\nHighlighted packages\nThe dashboard uses data.table, duckdb, fst, and purrr."
  },
  {
    "objectID": "projects/owi.html",
    "href": "projects/owi.html",
    "title": "Analysis of OWI ratios",
    "section": "",
    "text": "What I learned\nThis project involved the compilation of 5 data sets to calculate OWI (operating while intoxicated) ratios broken down by age group, race and sex. In order to combine these datasets, I had to rename columns and recode variables so datasets can be joined. The entire analysis I wrote functions to allow for any combo of age, sex, and race (the variables the study involved).\n\n\nHighlighted packages\ndata.table, dplyr"
  },
  {
    "objectID": "projects/template.html",
    "href": "projects/template.html",
    "title": "WisDOT Crash Statistics Dashboard",
    "section": "",
    "text": "What I learned\nThrough performance testing via shinyloadtest, I found an enormous bottleneck through simply loading the data. As a solution, I created a SQLite database as the database is saved locally inside the package. While this dramitically improved performance, data was still being mapped on-the-fly. Ideally the data should be stored in a spatial database. This app also uses modules so server and ui are much cleaner while the code is easier to debug.\n\n\nHighlighted packages\nplotly, leaflet, leaflet.extras2 and leafgl under a golem framework."
  },
  {
    "objectID": "projects/cv.html",
    "href": "projects/cv.html",
    "title": "cv",
    "section": "",
    "text": "Wisconsin Department of Health Services\n\n\nIS Business Automation Specialist 6/2023 - Present\n\nBullet 1\nBullet 2\n\n\n\nHighway Safety Data Analyst 5/2019 – 6/2023\n\nDeveloped an R package that makes data pulls and data analysis much easier inside an R environment, slashing time spent fulfilling data requests into a manner of minutes/\nLearned Shiny to develop a Crash Dashboard with multi-selection capabilities, interactive charts, and a dynamic map\nWrote a parameterized R Markdown to fully automate the creation of 72 crash data county profiles (tinyurl.com/yckw8v6s)\nUsed an API to collect court case data then flattening JSON file, cleaning data, and running analysis Developed a Shiny dashboard to compare quarterly crash trends (communitymaps.wi.gov/crash/public/Dashboard/)\nImproved relationship between WisDOT and UW by establishing a set of uniform queries used for data pulls and crash analysis"
  },
  {
    "objectID": "projects/cv.html#professional-experience",
    "href": "projects/cv.html#professional-experience",
    "title": "cv",
    "section": "",
    "text": "Wisconsin Department of Health Services\n\n\nIS Business Automation Specialist 6/2023 - Present\n\nBullet 1\nBullet 2\n\n\n\nHighway Safety Data Analyst 5/2019 – 6/2023\n\nDeveloped an R package that makes data pulls and data analysis much easier inside an R environment, slashing time spent fulfilling data requests into a manner of minutes/\nLearned Shiny to develop a Crash Dashboard with multi-selection capabilities, interactive charts, and a dynamic map\nWrote a parameterized R Markdown to fully automate the creation of 72 crash data county profiles (tinyurl.com/yckw8v6s)\nUsed an API to collect court case data then flattening JSON file, cleaning data, and running analysis Developed a Shiny dashboard to compare quarterly crash trends (communitymaps.wi.gov/crash/public/Dashboard/)\nImproved relationship between WisDOT and UW by establishing a set of uniform queries used for data pulls and crash analysis"
  },
  {
    "objectID": "projects/cv.html#awards",
    "href": "projects/cv.html#awards",
    "title": "cv",
    "section": " Awards",
    "text": "Awards"
  },
  {
    "objectID": "projects/lost_city.html",
    "href": "projects/lost_city.html",
    "title": "Madison’s ‘Lost City’ - A Look Into the Failed 1920’s Lake Forest Development",
    "section": "",
    "text": "I wrote this article in 2016 and it was originally posted on Imgur.\n\nA map geek, a planning enthusiast and a sucker for the unknown, I decided to delve a little deeper into one of Madison’s greatest mysteries, the “Lost City.” You may be thinking, “Is it even real?” or “Why the heck are there paved paths in the Arboretum?” After scoping out online resources, a visit to the Wisconsin Historical Society, and an in-situ visit to the area, I want to share what I found.\nLet’s start with some context of planning. The industrial revolution brought an influx of people to flock to urban areas. By the late 1910s, it was the first time in human history that the country’s urban population outnumbered the rural population. This brought on the perception that cities were rifled with poor sanitation, terrible pollution, and overcrowding. Areas that were once used as public space or parks were now houses, businesses, and industries. People wanted to escape dirty, crowded cities, but did not want to live in farm country.\n\nStarting in the 1890s and lasting til the 1920s, a new wave of planning cities emerged deemed the City Beautiful Movement. Led by developers, planners, and architects, the idea was that classic beauty and monumental grandeur of the city would inspire feelings of civic loyalty and moral rectitude. By incorporating civic centers, parks, and grand boulevards, city beautification would reduce crime, reduce density, and increase green space. While Madison was already established as being a pristine place to live, there were worries with what the city’s predicted continued growth will lead.\n\nDeveloper and president of the Lake Forest Company, Chandler B. Chapman attempted to hop on the bandwagon in taking one step further in beautifying Madison by building a residential paradise called Lake Forest. An 800-acre epic development with over 1,000 lots, Lake Forest would be an escape from city life with numerous parks, its own public transit, and a city center. The company promoted Lake Forest by calling it “by far the best planned city residential section in Wisconsin” and “the most beautiful, modern, healthful, and desirable dwelling spot in the Northeast.”\n\nThis southeastern section of the development was started with many of the roads built along with a few houses.\n Note: Block A is the Civic Center and Block B is St. Cyr Circle while Capitol Avenue intersects these two circles.  \nThe center of life for Lake Forest residents, the Civic Center was planned to have small shops and businesses lined around the circle. Separating land uses, such as commercial, industrial, and residential, was a new phenomenon in planning. The only building still standing today is the pumping station which, I believe, is still in use.\n\nA network of lagoons were proposed for two prominent reasons: to provide waterfront access to residents and to stabilize the marshy grounds.\n\nThis was one grandeur development! To entice people in purchasing property, the company heavily advertised. Above is a 1920 advertisement placed in the Wisconsin State Journal. Additionally, a bimonthly newsletter called the “Lake Forester” that ran for 1.5 years from 1921-1922 was written to chronicle the progress of the development.\n\nIn 1921, the Lake Forest Company broke grounds: roads were pored with concrete, dredging was being done and housing foundations were laid. This is Capital Avenue under construction. Planned to be 120 feet wide with sidewalks on each side with an unforgettable view of the Capital Building, the size would have been comparable to Washington Avenue today. Street cars were planned to run in the center, providing transportation to the downtown. You can see St. Mary’s Hospital to the slight left.\n\nWhile at least five houses (some sources say 7 houses) were completed, none of them were ever occupied. EDIT: 10/8/2016 An Arboretum researcher says some of the houses are actually still standing and occupied.\n\nWhat happened next, nobody foresaw. A combination of problems led to the collapse and eventual decay of the development. Dredging proved insufficient: roads and foundations were sinking due to marshy soils. In 1920, only 61 lots were sold while the company’s financial planner went bankrupt. The Great Depression and World War II didn’t help either. Strapped for cash, the Lake Forest Company sold some of the land to the University of Wisconsin for arboretum purposes in the 1930s. Ultimately the development failed. This area today is the Lost City Forest in the Arboretum, perhaps a different kind of paradise.\n\nYup, there’s actually Indian effigy mounds here!  This 1941 plat map shows two effigy mounds located north of Lake Forest. Furthermore, a hand-drawn 1915 map of effigy mounds I found on Arboretum’s online map shows a group of four mounds here, one looking like a panther. Today this is now a residential area around Marshall Parkway. It’s private property and I wonder if the mounds still exist,\nThe mound site at St. Cyr Circle the article mentions, I found no records of a panther mound here. The 1915 map shows two long narrow mounds at this location while another map indicates that no mounds exist. However, there is a large group of at least 8 mounds located inside Wingra Woods, just west of Lake Forest.\n\nA 1937 aerial photo of the area shows the remains of this epic development. As you can seen, only some of the roads were completed. Today the roads east of the former Civic Center is completely developed with houses and apartments, while the other roads remain crumbling into history.\n\nToday, not much remains. A walk into Lost City Forest you find mysteriously paved paths nearly a century old. If you look at the Imagery basemap at ArcGIS.com you could actually see outlines of these roads.\n My findings cannot be complete without a stroll through the woods!\n\n\nI bet some of you are tempted to look for the remains. The Arboretum hosts a once-a-year Lost City tour, typically at the end of October. I went to the presentation and I highly recommend it.\nThe Arboretum advises hikers to not wonder off the trails as to protect the environment. I don’t want to encourage nor discourage people from doing so, just wanted to share a piece of this fascinating mystery.\nIf you’re curious, a few adventurers sought to find the Lost City. Check ’em out here:\n\nhttps://badgerherald.com/artsetc/2015/09/14/madisons-lost-city-inside-the-forgotten-remains-of-lake-forest/\nhttp://never365.blogspot.com/2013/11/day-177-finding-lost-city.html\nhttps://www.youtube.com/watch?v=GpYXDLR4_f0&feature=youtu.be\n\nHope you enjoyed this!\nSources:\n\nArcGIS Online\nLake Forester, 1920 - 1921 found at University of Wisconsin Collection\nMadison:the illustrated sesquicentennial history Vol. 1 1856 - 1931\nWisconsin Historical Aerial Image Finder\nWisconsin Historical Society"
  },
  {
    "objectID": "projects/bike_map.html",
    "href": "projects/bike_map.html",
    "title": "Subway-Style Bike Path Map of Madison, WI",
    "section": "",
    "text": "What I learned\nI wanted to learn Adobe Illustrator, so I made a bike map path of Madison, WI. I started off with using QGIS to get the streets. Then in Illustrator, I kind of traced over these roads. As I wanted to maintain the subway style, the rule was that polygons had to use 45 degree angles."
  }
]